{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<p style:color='green'>Cross Validation</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbd7ddf09f763af4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation scores (5 folds): [0.98245614 0.98245614 0.97368421 0.97368421 0.99115044]\n",
      "the average cross-validation score (5 folds): 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# normalizing data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "scores = cross_val_score(logreg, X_scaled, y, cv=5)\n",
    "\n",
    "print('cross-validation scores (5 folds): {}'.format(scores))\n",
    "print('the average cross-validation score (5 folds): {:.2f}'.format(np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T03:44:03.224346400Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   fit_time  score_time  test_score  train_score\n0  0.015619     0.00000    0.982456     0.991209\n1  0.015625     0.00000    0.982456     0.989011\n2  0.031241     0.00000    0.973684     0.989011\n3  0.023845     0.00000    0.973684     0.991209\n4  0.031245     0.03125    0.991150     0.986842",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.015619</td>\n      <td>0.00000</td>\n      <td>0.982456</td>\n      <td>0.991209</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.015625</td>\n      <td>0.00000</td>\n      <td>0.982456</td>\n      <td>0.989011</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.031241</td>\n      <td>0.00000</td>\n      <td>0.973684</td>\n      <td>0.989011</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.023845</td>\n      <td>0.00000</td>\n      <td>0.973684</td>\n      <td>0.991209</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.031245</td>\n      <td>0.03125</td>\n      <td>0.991150</td>\n      <td>0.986842</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean time and score:\n",
      " fit_time       0.023515\n",
      "score_time     0.006250\n",
      "test_score     0.980686\n",
      "train_score    0.989456\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "res = cross_validate(logreg, X_scaled, y, cv=5, return_train_score=True)\n",
    "\n",
    "res_df = pd.DataFrame(res)\n",
    "display(res_df)\n",
    "print('mean time and score:\\n', res_df.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:15.781649Z",
     "start_time": "2023-12-05T03:53:15.571942400Z"
    }
   },
   "id": "cde48e2759b72010"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast_cancer targets:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print('breast_cancer targets:\\n{}'.format(y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:16.187682800Z",
     "start_time": "2023-12-05T03:53:16.156438500Z"
    }
   },
   "id": "c2c0720236949ef8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation scores (3 folds): [0.97894737 0.97368421 0.97354497]\n",
      "the average cross-validation score (3 folds): 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# stratified 3-fold splits (3 iterations)\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "bcl = LogisticRegression()\n",
    "skf_scores = cross_val_score(bcl, X_scaled, y, cv=skf)\n",
    "\n",
    "print('cross-validation scores (3 folds): {}'.format(skf_scores))\n",
    "print('the average cross-validation score (3 folds): {:.2f}'.format(np.mean(skf_scores)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:18.076996600Z",
     "start_time": "2023-12-05T03:53:17.976815900Z"
    }
   },
   "id": "b4b8cbc74d5423b8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy value of cross-validation:\n",
      "[0.96315789 0.97894737 0.97354497]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k_fold = KFold(n_splits=3)\n",
    "\n",
    "print('accuracy value of cross-validation:\\n{}'.format(cross_val_score(logreg, X_scaled, y, cv=k_fold)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:19.696350400Z",
     "start_time": "2023-12-05T03:53:19.593588300Z"
    }
   },
   "id": "54550a5c6ae9ab6a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy value of cross-validation:\n",
      "[0.97894737 0.95789474 0.98941799]\n"
     ]
    }
   ],
   "source": [
    "fold_k = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print('accuracy value of cross-validation:\\n{}'.format(cross_val_score(logreg, X_scaled, y, cv=fold_k)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:20.556306400Z",
     "start_time": "2023-12-05T03:53:20.446962300Z"
    }
   },
   "id": "bcb489d56ee97efe"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iterations:  569\n",
      "the average cross validation score: 0.9789103690685413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# leave one out splits\n",
    "loo = LeaveOneOut()\n",
    "loo_scores = cross_val_score(logreg, X_scaled, y, cv=loo)\n",
    "\n",
    "print('number of iterations: ', len(loo_scores))\n",
    "print('the average cross validation score: {}'.format(np.mean(loo_scores)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:33.161776600Z",
     "start_time": "2023-12-05T03:53:21.298577700Z"
    }
   },
   "id": "c4d093dbc2f3e230"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy vaues of shuffle-split cross-validation:\n",
      "[0.97894737 0.98245614 0.96491228 0.9754386  0.95087719 0.98596491\n",
      " 0.97894737 0.97192982 0.96842105 0.98245614]\n",
      "the average cross validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "\n",
    "shuffle_scores = cross_val_score(logreg, X_scaled, y, cv=shuffle_split)\n",
    "print('accuracy values of shuffle-split cross-validation:\\n{}'.format(shuffle_scores))\n",
    "print('the average cross validation score: {:.2f}'.format(np.mean(shuffle_scores)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:33.286583900Z",
     "start_time": "2023-12-05T03:53:33.161776600Z"
    }
   },
   "id": "333144b137c640c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style:color='green'>Grid Search</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e6f7030f65ec4a2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape: 426, test train shape: 143\n",
      "C:  0.001 penalty:  l1 accuracy: 0.916\n",
      "C:  0.001 penalty:  l2 accuracy: 0.944\n",
      "C:  0.1 penalty:  l1 accuracy: 0.944\n",
      "C:  0.1 penalty:  l2 accuracy: 0.937\n",
      "C:  1 penalty:  l1 accuracy: 0.937\n",
      "C:  1 penalty:  l2 accuracy: 0.937\n",
      "C:  10 penalty:  l1 accuracy: 0.937\n",
      "C:  10 penalty:  l2 accuracy: 0.937\n",
      "the best accuracy value: 0.944\n",
      "the best parameter values: {'C': 0.001, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer_X = breast_cancer.data\n",
    "cancer_y = breast_cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_X, cancer_y, random_state=0)\n",
    "print('train set shape: {}, test train shape: {}'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "for C in [0.001, 0.1, 1, 10]:\n",
    "    # l1 regularization - lasso, l2 reg - ridge\n",
    "    for penalty in ['l1', 'l2']:\n",
    "        logr = LogisticRegression(C=C, penalty=penalty, solver='saga', max_iter=10000)\n",
    "        logr.fit(X_train, y_train)\n",
    "        l_score = logr.score(X_test, y_test)\n",
    "        print('C: ', C, 'penalty: ', penalty, 'accuracy: {:.3f}'.format(l_score))\n",
    "\n",
    "        if l_score > best_score:\n",
    "            best_score = l_score\n",
    "            best_parameters = {'C': C, 'penalty': penalty}\n",
    "\n",
    "print('the best accuracy value: {:.3f}'.format(best_score))\n",
    "print('the best parameter values: {}'.format(best_parameters))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T03:53:36.669392400Z"
    }
   },
   "id": "6e430182432612e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best SVM score:  0.9300699300699301\n",
      "best parameters:  (0.001, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "best_svc = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        s_score = svm.score(X_test, y_test)\n",
    "\n",
    "        if s_score > best_svc:\n",
    "            best_svc = s_score\n",
    "            best_svc_parameters = (gamma, C)\n",
    "\n",
    "print('best SVM score: ', best_svc)\n",
    "print('best parameters: ', best_svc_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:51.822141300Z",
     "start_time": "2023-12-05T03:53:49.817010Z"
    }
   },
   "id": "6413ad677710d475"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best dt score:  0.9370629370629371\n",
      "best dt max_depth param:  2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "best_dt = 0\n",
    "for max_depth in [1, 2, 3, 5, 7, 9, 11]:\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth, random_state=0)\n",
    "    dt.fit(X_train, y_train)\n",
    "    d_score = dt.score(X_test, y_test)\n",
    "\n",
    "    if d_score > best_dt:\n",
    "        best_dt = d_score\n",
    "        best_dt_param = max_depth\n",
    "\n",
    "print('best dt score: ', best_dt)\n",
    "print('best dt max_depth param: ', best_dt_param)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:53:53.041339Z",
     "start_time": "2023-12-05T03:53:52.741577400Z"
    }
   },
   "id": "253ce76980a30618"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.9440559440559441\n",
      "best params:  {'C': 0.001, 'penalty': 'l2'}\n",
      "best score:  0.9130506155950752\n",
      "whole args view : LogisticRegression(C=0.001, max_iter=10000, solver='saga')\n"
     ]
    },
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n0       0.502404      0.138890         0.000256        0.000512   0.001   \n1       0.435685      0.070410         0.000000        0.000000   0.001   \n2       0.638756      0.073445         0.000000        0.000000     0.1   \n3       0.477640      0.022961         0.000000        0.000000     0.1   \n4       0.643096      0.044727         0.000000        0.000000       1   \n\n  param_penalty                         params  split0_test_score  \\\n0            l1  {'C': 0.001, 'penalty': 'l1'}           0.965116   \n1            l2  {'C': 0.001, 'penalty': 'l2'}           0.953488   \n2            l1    {'C': 0.1, 'penalty': 'l1'}           0.953488   \n3            l2    {'C': 0.1, 'penalty': 'l2'}           0.953488   \n4            l1      {'C': 1, 'penalty': 'l1'}           0.953488   \n\n   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n0           0.858824           0.894118           0.941176           0.905882   \n1           0.870588           0.929412           0.894118           0.917647   \n2           0.858824           0.929412           0.894118           0.917647   \n3           0.858824           0.917647           0.894118           0.917647   \n4           0.858824           0.917647           0.894118           0.917647   \n\n   mean_test_score  std_test_score  rank_test_score  \n0         0.913023        0.037020                2  \n1         0.913051        0.028585                1  \n2         0.910698        0.032235                3  \n3         0.908345        0.031195                4  \n4         0.908345        0.031195                4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_C</th>\n      <th>param_penalty</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.502404</td>\n      <td>0.138890</td>\n      <td>0.000256</td>\n      <td>0.000512</td>\n      <td>0.001</td>\n      <td>l1</td>\n      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n      <td>0.965116</td>\n      <td>0.858824</td>\n      <td>0.894118</td>\n      <td>0.941176</td>\n      <td>0.905882</td>\n      <td>0.913023</td>\n      <td>0.037020</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.435685</td>\n      <td>0.070410</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001</td>\n      <td>l2</td>\n      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n      <td>0.953488</td>\n      <td>0.870588</td>\n      <td>0.929412</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.913051</td>\n      <td>0.028585</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.638756</td>\n      <td>0.073445</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>l1</td>\n      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.929412</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.910698</td>\n      <td>0.032235</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.477640</td>\n      <td>0.022961</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>l2</td>\n      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.643096</td>\n      <td>0.044727</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>l1</td>\n      <td>{'C': 1, 'penalty': 'l1'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grid search using sklearn lib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_grid = {'C': [0.001, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(solver='saga', max_iter=10000), lr_grid)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "score_gs = grid_search_lr.score(X_test, y_test)\n",
    "\n",
    "print('test score:', score_gs)\n",
    "print('best params: ', grid_search_lr.best_params_)\n",
    "print('best score: ', grid_search_lr.best_score_)\n",
    "print('whole args view :', grid_search_lr.best_estimator_)\n",
    "\n",
    "results = pd.DataFrame(grid_search_lr.cv_results_)\n",
    "display(results.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:54:19.753114100Z",
     "start_time": "2023-12-05T03:53:57.878723Z"
    }
   },
   "id": "5cbc38e8bb8d401f"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.9300699300699301\n",
      "best params:  {'C': 1, 'gamma': 0.001}\n",
      "best score:  0.9223803009575923\n",
      "whole args view : SVC(C=1, gamma=0.001)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n0       0.015736      0.000197         0.002923        0.005847   0.001   \n1       0.015616      0.000028         0.001508        0.003016   0.001   \n2       0.016930      0.002585         0.000000        0.000000   0.001   \n3       0.016887      0.002510         0.013772        0.009687   0.001   \n4       0.027943      0.005627         0.014064        0.001162   0.001   \n\n  param_gamma                        params  split0_test_score  \\\n0       0.001  {'C': 0.001, 'gamma': 0.001}           0.627907   \n1        0.01   {'C': 0.001, 'gamma': 0.01}           0.627907   \n2         0.1    {'C': 0.001, 'gamma': 0.1}           0.627907   \n3           1      {'C': 0.001, 'gamma': 1}           0.627907   \n4          10     {'C': 0.001, 'gamma': 10}           0.627907   \n\n   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n0           0.635294           0.623529           0.623529           0.623529   \n1           0.635294           0.623529           0.623529           0.623529   \n2           0.635294           0.623529           0.623529           0.623529   \n3           0.635294           0.623529           0.623529           0.623529   \n4           0.635294           0.623529           0.623529           0.623529   \n\n   mean_test_score  std_test_score  rank_test_score  \n0         0.626758        0.004593                6  \n1         0.626758        0.004593                6  \n2         0.626758        0.004593                6  \n3         0.626758        0.004593                6  \n4         0.626758        0.004593                6  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_C</th>\n      <th>param_gamma</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.015736</td>\n      <td>0.000197</td>\n      <td>0.002923</td>\n      <td>0.005847</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>{'C': 0.001, 'gamma': 0.001}</td>\n      <td>0.627907</td>\n      <td>0.635294</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.626758</td>\n      <td>0.004593</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.015616</td>\n      <td>0.000028</td>\n      <td>0.001508</td>\n      <td>0.003016</td>\n      <td>0.001</td>\n      <td>0.01</td>\n      <td>{'C': 0.001, 'gamma': 0.01}</td>\n      <td>0.627907</td>\n      <td>0.635294</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.626758</td>\n      <td>0.004593</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.016930</td>\n      <td>0.002585</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001</td>\n      <td>0.1</td>\n      <td>{'C': 0.001, 'gamma': 0.1}</td>\n      <td>0.627907</td>\n      <td>0.635294</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.626758</td>\n      <td>0.004593</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016887</td>\n      <td>0.002510</td>\n      <td>0.013772</td>\n      <td>0.009687</td>\n      <td>0.001</td>\n      <td>1</td>\n      <td>{'C': 0.001, 'gamma': 1}</td>\n      <td>0.627907</td>\n      <td>0.635294</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.626758</td>\n      <td>0.004593</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.027943</td>\n      <td>0.005627</td>\n      <td>0.014064</td>\n      <td>0.001162</td>\n      <td>0.001</td>\n      <td>10</td>\n      <td>{'C': 0.001, 'gamma': 10}</td>\n      <td>0.627907</td>\n      <td>0.635294</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.623529</td>\n      <td>0.626758</td>\n      <td>0.004593</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grid search using sklearn lib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid1 = {'gamma': [0.001, 0.01, 0.1, 1, 10, 100], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs1 = GridSearchCV(SVC(), grid1, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "gs1.fit(X_train, y_train)\n",
    "score1 = gs1.score(X_test, y_test)\n",
    "\n",
    "print('test score:', score1)\n",
    "print('best params: ', gs1.best_params_)\n",
    "print('best score: ', gs1.best_score_)\n",
    "print('whole args view :', gs1.best_estimator_)\n",
    "\n",
    "results1 = pd.DataFrame(gs1.cv_results_)\n",
    "display(results1.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T19:55:43.542625800Z",
     "start_time": "2023-12-04T19:55:39.254247300Z"
    }
   },
   "id": "c19e5b704cb7d1a9"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sc = np.array(results1.mean_test_score).reshape(6, 6)\n",
    "ax = sns.heatmap(sc, annot=True, xticklabels=grid1['gamma'], yticklabels=grid1['C'], cmap='hsv')\n",
    "ax.set(xlabel='gamma', ylabel='C')\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-04T19:59:03.096012700Z"
    }
   },
   "id": "259e822c49b5d24b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape: 319, validation set shape: 107, test set shape: 143\n",
      "best validation score:  0.8598130841121495\n",
      "best params:  {'C': 0.1, 'penalty': 'l1'}\n",
      "best score:  0.9436507936507936\n",
      "accuracy on test set with best params:  0.9440559440559441\n"
     ]
    }
   ],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=0)\n",
    "print('train set shape: {}, validation set shape: {}, test set shape: {}'.format(X_train.shape[0], X_valid.shape[0],\n",
    "                                                                                 X_test.shape[0]))\n",
    "\n",
    "grid_lr = GridSearchCV(LogisticRegression(solver='saga', max_iter=10000), lr_grid)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "validation_score = grid_lr.score(X_valid, y_valid)\n",
    "\n",
    "print('best validation score: ', validation_score)\n",
    "print('best params: ', grid_lr.best_params_)\n",
    "print('best score: ', grid_lr.best_score_)\n",
    "\n",
    "new_logreg = LogisticRegression(solver='saga', max_iter=10000, **grid_lr.best_params_)\n",
    "new_logreg.fit(X_trainval, y_trainval)\n",
    "test_score = new_logreg.score(X_test, y_test)\n",
    "\n",
    "print('accuracy on test set with best params: ', test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:55:08.144336200Z",
     "start_time": "2023-12-05T03:54:51.083381Z"
    }
   },
   "id": "123b962b7cbd15e8"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best logistic regression score:  0.9130506155950752\n",
      "best params:  {'C': 0.001, 'penalty': 'l2'}\n",
      "test accuracy:  0.9440559440559441\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "for C in [0.001, 0.1, 1, 10]:\n",
    "    for penalty in ['l1', 'l2']:\n",
    "        lr = LogisticRegression(solver='saga', max_iter=10000, C=C, penalty=penalty)\n",
    "        scoress = cross_val_score(lr, X_trainval, y_trainval, cv=5)\n",
    "        score = np.mean(scoress)\n",
    "\n",
    "        if score > best_lr:\n",
    "            best_lr = score\n",
    "            best_params = {'C': C, 'penalty': penalty}\n",
    "\n",
    "print('best logistic regression score: ', best_lr)\n",
    "print('best params: ', best_params)\n",
    "\n",
    "new_lr = LogisticRegression(solver='saga', max_iter=10000, **best_params).fit(X_trainval, y_trainval)\n",
    "score_test = new_lr.score(X_test, y_test)\n",
    "print('test accuracy: ', score_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T19:35:11.779950900Z",
     "start_time": "2023-12-04T19:34:48.761523200Z"
    }
   },
   "id": "3e212cca1aedfb10"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param values: {'C': 0.1, 'kernel': 'linear'}\n",
      "best cross-val accuracy value: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n0        0.006248      0.007652         0.006249        0.007653   0.001   \n1        0.009507      0.007766         0.000316        0.000632   0.001   \n2        0.008395      0.010828         0.003433        0.006124   0.001   \n3        0.009373      0.007653         0.006255        0.007661   0.001   \n4        0.009367      0.007648         0.003129        0.006258   0.001   \n5        0.012199      0.012735         0.004684        0.006247   0.001   \n6        0.006144      0.003907         0.008367        0.007559    0.01   \n7        0.018852      0.003923         0.008049        0.001145    0.01   \n8        0.026113      0.020659         0.002092        0.004185    0.01   \n9        0.003124      0.006249         0.012497        0.006249    0.01   \n10       0.015621      0.000015         0.000000        0.000000    0.01   \n11       0.009378      0.007657         0.006249        0.007653    0.01   \n12       0.003117      0.006235         0.006249        0.007654     0.1   \n13       0.006255      0.007661         0.006248        0.007652     0.1   \n14       0.008537      0.007136         0.003412        0.006825     0.1   \n15       0.009373      0.007653         0.006250        0.007654     0.1   \n16       0.009373      0.007653         0.003130        0.006260     0.1   \n17       0.009368      0.007649         0.006247        0.007651     0.1   \n18       0.003125      0.006250         0.006248        0.007652       1   \n19       0.009379      0.007658         0.003126        0.006252       1   \n20       0.012495      0.006247         0.003123        0.006247       1   \n21       0.008426      0.007097         0.002947        0.005894       1   \n22       0.006256      0.007662         0.006249        0.007653       1   \n23       0.012495      0.006248         0.003125        0.006251       1   \n24       0.006241      0.007643         0.003131        0.006262      10   \n25       0.006255      0.007660         0.006243        0.007646      10   \n26       0.006249      0.007653         0.006250        0.007654      10   \n27       0.012497      0.006248         0.003118        0.006235      10   \n28       0.009379      0.007658         0.003125        0.006250      10   \n29       0.015207      0.000815         0.000000        0.000000      10   \n30       0.006248      0.007652         0.003131        0.006262     100   \n31       0.009372      0.007652         0.003125        0.006251     100   \n32       0.006250      0.007655         0.009365        0.007647     100   \n33       0.009374      0.007653         0.000000        0.000000     100   \n34       0.012495      0.006248         0.003124        0.006248     100   \n35       0.000000      0.000000         0.012501        0.006250     100   \n36       0.003122      0.006244         0.003126        0.006251   0.001   \n37       0.009365      0.007646         0.000000        0.000000    0.01   \n38       0.038330      0.013223         0.000000        0.000000     0.1   \n39       0.379759      0.240808         0.006240        0.007643       1   \n40       4.097110      2.995786         0.000000        0.000000      10   \n41       4.147533      3.414533         0.003117        0.006233     100   \n\n   param_gamma param_kernel                                         params  \\\n0        0.001          rbf  {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}   \n1         0.01          rbf   {'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}   \n2          0.1          rbf    {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'}   \n3            1          rbf      {'C': 0.001, 'gamma': 1, 'kernel': 'rbf'}   \n4           10          rbf     {'C': 0.001, 'gamma': 10, 'kernel': 'rbf'}   \n5          100          rbf    {'C': 0.001, 'gamma': 100, 'kernel': 'rbf'}   \n6        0.001          rbf   {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}   \n7         0.01          rbf    {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}   \n8          0.1          rbf     {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}   \n9            1          rbf       {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}   \n10          10          rbf      {'C': 0.01, 'gamma': 10, 'kernel': 'rbf'}   \n11         100          rbf     {'C': 0.01, 'gamma': 100, 'kernel': 'rbf'}   \n12       0.001          rbf    {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}   \n13        0.01          rbf     {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}   \n14         0.1          rbf      {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}   \n15           1          rbf        {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}   \n16          10          rbf       {'C': 0.1, 'gamma': 10, 'kernel': 'rbf'}   \n17         100          rbf      {'C': 0.1, 'gamma': 100, 'kernel': 'rbf'}   \n18       0.001          rbf      {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}   \n19        0.01          rbf       {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}   \n20         0.1          rbf        {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}   \n21           1          rbf          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n22          10          rbf         {'C': 1, 'gamma': 10, 'kernel': 'rbf'}   \n23         100          rbf        {'C': 1, 'gamma': 100, 'kernel': 'rbf'}   \n24       0.001          rbf     {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n25        0.01          rbf      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n26         0.1          rbf       {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}   \n27           1          rbf         {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n28          10          rbf        {'C': 10, 'gamma': 10, 'kernel': 'rbf'}   \n29         100          rbf       {'C': 10, 'gamma': 100, 'kernel': 'rbf'}   \n30       0.001          rbf    {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n31        0.01          rbf     {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}   \n32         0.1          rbf      {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}   \n33           1          rbf        {'C': 100, 'gamma': 1, 'kernel': 'rbf'}   \n34          10          rbf       {'C': 100, 'gamma': 10, 'kernel': 'rbf'}   \n35         100          rbf      {'C': 100, 'gamma': 100, 'kernel': 'rbf'}   \n36         NaN       linear               {'C': 0.001, 'kernel': 'linear'}   \n37         NaN       linear                {'C': 0.01, 'kernel': 'linear'}   \n38         NaN       linear                 {'C': 0.1, 'kernel': 'linear'}   \n39         NaN       linear                   {'C': 1, 'kernel': 'linear'}   \n40         NaN       linear                  {'C': 10, 'kernel': 'linear'}   \n41         NaN       linear                 {'C': 100, 'kernel': 'linear'}   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n0            0.625000           0.640625           0.640625   \n1            0.625000           0.640625           0.640625   \n2            0.625000           0.640625           0.640625   \n3            0.625000           0.640625           0.640625   \n4            0.625000           0.640625           0.640625   \n5            0.625000           0.640625           0.640625   \n6            0.625000           0.640625           0.640625   \n7            0.625000           0.640625           0.640625   \n8            0.625000           0.640625           0.640625   \n9            0.625000           0.640625           0.640625   \n10           0.625000           0.640625           0.640625   \n11           0.625000           0.640625           0.640625   \n12           0.625000           0.640625           0.640625   \n13           0.625000           0.640625           0.640625   \n14           0.625000           0.640625           0.640625   \n15           0.625000           0.640625           0.640625   \n16           0.625000           0.640625           0.640625   \n17           0.625000           0.640625           0.640625   \n18           0.937500           0.875000           0.875000   \n19           0.625000           0.640625           0.625000   \n20           0.625000           0.640625           0.640625   \n21           0.625000           0.640625           0.640625   \n22           0.625000           0.640625           0.640625   \n23           0.625000           0.640625           0.640625   \n24           0.937500           0.859375           0.875000   \n25           0.625000           0.640625           0.625000   \n26           0.625000           0.640625           0.640625   \n27           0.625000           0.640625           0.640625   \n28           0.625000           0.640625           0.640625   \n29           0.625000           0.640625           0.640625   \n30           0.937500           0.859375           0.875000   \n31           0.625000           0.640625           0.625000   \n32           0.625000           0.640625           0.640625   \n33           0.625000           0.640625           0.640625   \n34           0.625000           0.640625           0.640625   \n35           0.625000           0.640625           0.640625   \n36           0.968750           0.937500           0.890625   \n37           0.953125           0.953125           0.890625   \n38           0.953125           0.968750           0.937500   \n39           0.937500           0.968750           0.937500   \n40           0.937500           0.968750           0.890625   \n41           0.937500           0.968750           0.906250   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n0            0.640625           0.634921         0.636359        0.006094   \n1            0.640625           0.634921         0.636359        0.006094   \n2            0.640625           0.634921         0.636359        0.006094   \n3            0.640625           0.634921         0.636359        0.006094   \n4            0.640625           0.634921         0.636359        0.006094   \n5            0.640625           0.634921         0.636359        0.006094   \n6            0.640625           0.634921         0.636359        0.006094   \n7            0.640625           0.634921         0.636359        0.006094   \n8            0.640625           0.634921         0.636359        0.006094   \n9            0.640625           0.634921         0.636359        0.006094   \n10           0.640625           0.634921         0.636359        0.006094   \n11           0.640625           0.634921         0.636359        0.006094   \n12           0.640625           0.634921         0.636359        0.006094   \n13           0.640625           0.634921         0.636359        0.006094   \n14           0.640625           0.634921         0.636359        0.006094   \n15           0.640625           0.634921         0.636359        0.006094   \n16           0.640625           0.634921         0.636359        0.006094   \n17           0.640625           0.634921         0.636359        0.006094   \n18           0.937500           0.968254         0.918651        0.037368   \n19           0.640625           0.634921         0.633234        0.007038   \n20           0.640625           0.634921         0.636359        0.006094   \n21           0.640625           0.634921         0.636359        0.006094   \n22           0.640625           0.634921         0.636359        0.006094   \n23           0.640625           0.634921         0.636359        0.006094   \n24           0.937500           0.968254         0.915526        0.041331   \n25           0.640625           0.634921         0.633234        0.007038   \n26           0.640625           0.634921         0.636359        0.006094   \n27           0.640625           0.634921         0.636359        0.006094   \n28           0.640625           0.634921         0.636359        0.006094   \n29           0.640625           0.634921         0.636359        0.006094   \n30           0.937500           0.968254         0.915526        0.041331   \n31           0.640625           0.634921         0.633234        0.007038   \n32           0.640625           0.634921         0.636359        0.006094   \n33           0.640625           0.634921         0.636359        0.006094   \n34           0.640625           0.634921         0.636359        0.006094   \n35           0.640625           0.634921         0.636359        0.006094   \n36           0.968750           0.984127         0.949950        0.033315   \n37           0.984375           0.984127         0.953075        0.034187   \n38           0.984375           0.968254         0.962401        0.015897   \n39           0.968750           0.968254         0.956151        0.015229   \n40           0.968750           0.920635         0.937252        0.029781   \n41           0.968750           0.952381         0.946726        0.023347   \n\n    rank_test_score  \n0                10  \n1                10  \n2                10  \n3                10  \n4                10  \n5                10  \n6                10  \n7                10  \n8                10  \n9                10  \n10               10  \n11               10  \n12               10  \n13               10  \n14               10  \n15               10  \n16               10  \n17               10  \n18                7  \n19               40  \n20               10  \n21               10  \n22               10  \n23               10  \n24                8  \n25               40  \n26               10  \n27               10  \n28               10  \n29               10  \n30                8  \n31               40  \n32               10  \n33               10  \n34               10  \n35               10  \n36                4  \n37                3  \n38                1  \n39                2  \n40                6  \n41                5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_C</th>\n      <th>param_gamma</th>\n      <th>param_kernel</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.006248</td>\n      <td>0.007652</td>\n      <td>0.006249</td>\n      <td>0.007653</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.009507</td>\n      <td>0.007766</td>\n      <td>0.000316</td>\n      <td>0.000632</td>\n      <td>0.001</td>\n      <td>0.01</td>\n      <td>rbf</td>\n      <td>{'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.008395</td>\n      <td>0.010828</td>\n      <td>0.003433</td>\n      <td>0.006124</td>\n      <td>0.001</td>\n      <td>0.1</td>\n      <td>rbf</td>\n      <td>{'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.009373</td>\n      <td>0.007653</td>\n      <td>0.006255</td>\n      <td>0.007661</td>\n      <td>0.001</td>\n      <td>1</td>\n      <td>rbf</td>\n      <td>{'C': 0.001, 'gamma': 1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.009367</td>\n      <td>0.007648</td>\n      <td>0.003129</td>\n      <td>0.006258</td>\n      <td>0.001</td>\n      <td>10</td>\n      <td>rbf</td>\n      <td>{'C': 0.001, 'gamma': 10, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.012199</td>\n      <td>0.012735</td>\n      <td>0.004684</td>\n      <td>0.006247</td>\n      <td>0.001</td>\n      <td>100</td>\n      <td>rbf</td>\n      <td>{'C': 0.001, 'gamma': 100, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.006144</td>\n      <td>0.003907</td>\n      <td>0.008367</td>\n      <td>0.007559</td>\n      <td>0.01</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.018852</td>\n      <td>0.003923</td>\n      <td>0.008049</td>\n      <td>0.001145</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>rbf</td>\n      <td>{'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.026113</td>\n      <td>0.020659</td>\n      <td>0.002092</td>\n      <td>0.004185</td>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>rbf</td>\n      <td>{'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.003124</td>\n      <td>0.006249</td>\n      <td>0.012497</td>\n      <td>0.006249</td>\n      <td>0.01</td>\n      <td>1</td>\n      <td>rbf</td>\n      <td>{'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.015621</td>\n      <td>0.000015</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.01</td>\n      <td>10</td>\n      <td>rbf</td>\n      <td>{'C': 0.01, 'gamma': 10, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.009378</td>\n      <td>0.007657</td>\n      <td>0.006249</td>\n      <td>0.007653</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>rbf</td>\n      <td>{'C': 0.01, 'gamma': 100, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.003117</td>\n      <td>0.006235</td>\n      <td>0.006249</td>\n      <td>0.007654</td>\n      <td>0.1</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.006255</td>\n      <td>0.007661</td>\n      <td>0.006248</td>\n      <td>0.007652</td>\n      <td>0.1</td>\n      <td>0.01</td>\n      <td>rbf</td>\n      <td>{'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.008537</td>\n      <td>0.007136</td>\n      <td>0.003412</td>\n      <td>0.006825</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>rbf</td>\n      <td>{'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.009373</td>\n      <td>0.007653</td>\n      <td>0.006250</td>\n      <td>0.007654</td>\n      <td>0.1</td>\n      <td>1</td>\n      <td>rbf</td>\n      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.009373</td>\n      <td>0.007653</td>\n      <td>0.003130</td>\n      <td>0.006260</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>rbf</td>\n      <td>{'C': 0.1, 'gamma': 10, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.009368</td>\n      <td>0.007649</td>\n      <td>0.006247</td>\n      <td>0.007651</td>\n      <td>0.1</td>\n      <td>100</td>\n      <td>rbf</td>\n      <td>{'C': 0.1, 'gamma': 100, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.003125</td>\n      <td>0.006250</td>\n      <td>0.006248</td>\n      <td>0.007652</td>\n      <td>1</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.937500</td>\n      <td>0.875000</td>\n      <td>0.875000</td>\n      <td>0.937500</td>\n      <td>0.968254</td>\n      <td>0.918651</td>\n      <td>0.037368</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.009379</td>\n      <td>0.007658</td>\n      <td>0.003126</td>\n      <td>0.006252</td>\n      <td>1</td>\n      <td>0.01</td>\n      <td>rbf</td>\n      <td>{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.633234</td>\n      <td>0.007038</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.012495</td>\n      <td>0.006247</td>\n      <td>0.003123</td>\n      <td>0.006247</td>\n      <td>1</td>\n      <td>0.1</td>\n      <td>rbf</td>\n      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.008426</td>\n      <td>0.007097</td>\n      <td>0.002947</td>\n      <td>0.005894</td>\n      <td>1</td>\n      <td>1</td>\n      <td>rbf</td>\n      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.006256</td>\n      <td>0.007662</td>\n      <td>0.006249</td>\n      <td>0.007653</td>\n      <td>1</td>\n      <td>10</td>\n      <td>rbf</td>\n      <td>{'C': 1, 'gamma': 10, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.012495</td>\n      <td>0.006248</td>\n      <td>0.003125</td>\n      <td>0.006251</td>\n      <td>1</td>\n      <td>100</td>\n      <td>rbf</td>\n      <td>{'C': 1, 'gamma': 100, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.006241</td>\n      <td>0.007643</td>\n      <td>0.003131</td>\n      <td>0.006262</td>\n      <td>10</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.937500</td>\n      <td>0.859375</td>\n      <td>0.875000</td>\n      <td>0.937500</td>\n      <td>0.968254</td>\n      <td>0.915526</td>\n      <td>0.041331</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.006255</td>\n      <td>0.007660</td>\n      <td>0.006243</td>\n      <td>0.007646</td>\n      <td>10</td>\n      <td>0.01</td>\n      <td>rbf</td>\n      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.633234</td>\n      <td>0.007038</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.006249</td>\n      <td>0.007653</td>\n      <td>0.006250</td>\n      <td>0.007654</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>rbf</td>\n      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.012497</td>\n      <td>0.006248</td>\n      <td>0.003118</td>\n      <td>0.006235</td>\n      <td>10</td>\n      <td>1</td>\n      <td>rbf</td>\n      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.009379</td>\n      <td>0.007658</td>\n      <td>0.003125</td>\n      <td>0.006250</td>\n      <td>10</td>\n      <td>10</td>\n      <td>rbf</td>\n      <td>{'C': 10, 'gamma': 10, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.015207</td>\n      <td>0.000815</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>100</td>\n      <td>rbf</td>\n      <td>{'C': 10, 'gamma': 100, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.006248</td>\n      <td>0.007652</td>\n      <td>0.003131</td>\n      <td>0.006262</td>\n      <td>100</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.937500</td>\n      <td>0.859375</td>\n      <td>0.875000</td>\n      <td>0.937500</td>\n      <td>0.968254</td>\n      <td>0.915526</td>\n      <td>0.041331</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.009372</td>\n      <td>0.007652</td>\n      <td>0.003125</td>\n      <td>0.006251</td>\n      <td>100</td>\n      <td>0.01</td>\n      <td>rbf</td>\n      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.633234</td>\n      <td>0.007038</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.006250</td>\n      <td>0.007655</td>\n      <td>0.009365</td>\n      <td>0.007647</td>\n      <td>100</td>\n      <td>0.1</td>\n      <td>rbf</td>\n      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.009374</td>\n      <td>0.007653</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>100</td>\n      <td>1</td>\n      <td>rbf</td>\n      <td>{'C': 100, 'gamma': 1, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.012495</td>\n      <td>0.006248</td>\n      <td>0.003124</td>\n      <td>0.006248</td>\n      <td>100</td>\n      <td>10</td>\n      <td>rbf</td>\n      <td>{'C': 100, 'gamma': 10, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012501</td>\n      <td>0.006250</td>\n      <td>100</td>\n      <td>100</td>\n      <td>rbf</td>\n      <td>{'C': 100, 'gamma': 100, 'kernel': 'rbf'}</td>\n      <td>0.625000</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.640625</td>\n      <td>0.634921</td>\n      <td>0.636359</td>\n      <td>0.006094</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.003122</td>\n      <td>0.006244</td>\n      <td>0.003126</td>\n      <td>0.006251</td>\n      <td>0.001</td>\n      <td>NaN</td>\n      <td>linear</td>\n      <td>{'C': 0.001, 'kernel': 'linear'}</td>\n      <td>0.968750</td>\n      <td>0.937500</td>\n      <td>0.890625</td>\n      <td>0.968750</td>\n      <td>0.984127</td>\n      <td>0.949950</td>\n      <td>0.033315</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.009365</td>\n      <td>0.007646</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.01</td>\n      <td>NaN</td>\n      <td>linear</td>\n      <td>{'C': 0.01, 'kernel': 'linear'}</td>\n      <td>0.953125</td>\n      <td>0.953125</td>\n      <td>0.890625</td>\n      <td>0.984375</td>\n      <td>0.984127</td>\n      <td>0.953075</td>\n      <td>0.034187</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.038330</td>\n      <td>0.013223</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>linear</td>\n      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n      <td>0.953125</td>\n      <td>0.968750</td>\n      <td>0.937500</td>\n      <td>0.984375</td>\n      <td>0.968254</td>\n      <td>0.962401</td>\n      <td>0.015897</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.379759</td>\n      <td>0.240808</td>\n      <td>0.006240</td>\n      <td>0.007643</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>linear</td>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n      <td>0.937500</td>\n      <td>0.968750</td>\n      <td>0.937500</td>\n      <td>0.968750</td>\n      <td>0.968254</td>\n      <td>0.956151</td>\n      <td>0.015229</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>4.097110</td>\n      <td>2.995786</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>linear</td>\n      <td>{'C': 10, 'kernel': 'linear'}</td>\n      <td>0.937500</td>\n      <td>0.968750</td>\n      <td>0.890625</td>\n      <td>0.968750</td>\n      <td>0.920635</td>\n      <td>0.937252</td>\n      <td>0.029781</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>4.147533</td>\n      <td>3.414533</td>\n      <td>0.003117</td>\n      <td>0.006233</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>linear</td>\n      <td>{'C': 100, 'kernel': 'linear'}</td>\n      <td>0.937500</td>\n      <td>0.968750</td>\n      <td>0.906250</td>\n      <td>0.968750</td>\n      <td>0.952381</td>\n      <td>0.946726</td>\n      <td>0.023347</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'kernel': ['rbf'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "              {'kernel': ['linear'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('best param values: {}'.format(grid_search.best_params_))\n",
    "print('best cross-val accuracy value: {:.2f}'.format(grid_search.best_score_))\n",
    "\n",
    "ress = pd.DataFrame(grid_search.cv_results_)\n",
    "ress"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T04:15:10.518120600Z",
     "start_time": "2023-12-05T04:14:24.265725600Z"
    }
   },
   "id": "9b3cabcbbf64e576"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param values: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "best cross-val accuracy value: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n0        0.674945      0.153823         0.000000        0.000000     0.1   \n1        0.598247      0.025637         0.000000        0.000000     0.1   \n2        0.662989      0.058078         0.000000        0.000000     0.1   \n3        0.707812      0.090939         0.000000        0.000000       1   \n4        0.624772      0.021910         0.000000        0.000000       1   \n5        0.623691      0.030731         0.000000        0.000000       1   \n6        0.701795      0.031361         0.003125        0.006249      10   \n7        0.794977      0.052686         0.000000        0.000000      10   \n8        0.633363      0.025593         0.000000        0.000000      10   \n9        0.588053      0.020702         0.000000        0.000000     0.1   \n10       0.538070      0.083039         0.000000        0.000000     0.1   \n11       0.662105      0.105800         0.000000        0.000000       1   \n12       0.455993      0.019478         0.000000        0.000000       1   \n13       0.628303      0.015658         0.000000        0.000000      10   \n14       0.458909      0.012996         0.000000        0.000000      10   \n15       0.318256      0.036306         0.000000        0.000000     0.1   \n16       0.685107      0.028028         0.000000        0.000000       1   \n17       1.277492      0.370640         0.000000        0.000000      10   \n\n   param_l1_ratio param_penalty param_solver  \\\n0             0.2    elasticnet         saga   \n1             0.5    elasticnet         saga   \n2             0.8    elasticnet         saga   \n3             0.2    elasticnet         saga   \n4             0.5    elasticnet         saga   \n5             0.8    elasticnet         saga   \n6             0.2    elasticnet         saga   \n7             0.5    elasticnet         saga   \n8             0.8    elasticnet         saga   \n9             NaN            l1         saga   \n10            NaN            l2         saga   \n11            NaN            l1         saga   \n12            NaN            l2         saga   \n13            NaN            l1         saga   \n14            NaN            l2         saga   \n15            NaN            l2        lbfgs   \n16            NaN            l2        lbfgs   \n17            NaN            l2        lbfgs   \n\n                                               params  split0_test_score  \\\n0   {'C': 0.1, 'l1_ratio': 0.2, 'penalty': 'elasti...           0.953488   \n1   {'C': 0.1, 'l1_ratio': 0.5, 'penalty': 'elasti...           0.953488   \n2   {'C': 0.1, 'l1_ratio': 0.8, 'penalty': 'elasti...           0.953488   \n3   {'C': 1, 'l1_ratio': 0.2, 'penalty': 'elasticn...           0.953488   \n4   {'C': 1, 'l1_ratio': 0.5, 'penalty': 'elasticn...           0.953488   \n5   {'C': 1, 'l1_ratio': 0.8, 'penalty': 'elasticn...           0.953488   \n6   {'C': 10, 'l1_ratio': 0.2, 'penalty': 'elastic...           0.953488   \n7   {'C': 10, 'l1_ratio': 0.5, 'penalty': 'elastic...           0.953488   \n8   {'C': 10, 'l1_ratio': 0.8, 'penalty': 'elastic...           0.953488   \n9       {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}           0.953488   \n10      {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}           0.953488   \n11        {'C': 1, 'penalty': 'l1', 'solver': 'saga'}           0.953488   \n12        {'C': 1, 'penalty': 'l2', 'solver': 'saga'}           0.953488   \n13       {'C': 10, 'penalty': 'l1', 'solver': 'saga'}           0.953488   \n14       {'C': 10, 'penalty': 'l2', 'solver': 'saga'}           0.953488   \n15     {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.988372   \n16       {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.988372   \n17      {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}           0.976744   \n\n    split1_test_score  split2_test_score  split3_test_score  \\\n0            0.858824           0.917647           0.894118   \n1            0.858824           0.917647           0.894118   \n2            0.858824           0.929412           0.894118   \n3            0.858824           0.917647           0.894118   \n4            0.858824           0.917647           0.894118   \n5            0.858824           0.917647           0.894118   \n6            0.858824           0.917647           0.894118   \n7            0.858824           0.917647           0.894118   \n8            0.858824           0.917647           0.894118   \n9            0.858824           0.929412           0.894118   \n10           0.858824           0.917647           0.894118   \n11           0.858824           0.917647           0.894118   \n12           0.858824           0.917647           0.894118   \n13           0.858824           0.917647           0.894118   \n14           0.858824           0.917647           0.894118   \n15           0.929412           0.905882           0.976471   \n16           0.941176           0.917647           0.976471   \n17           0.952941           0.917647           0.976471   \n\n    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n0            0.917647         0.908345        0.031195                6  \n1            0.917647         0.908345        0.031195                6  \n2            0.917647         0.910698        0.032235                4  \n3            0.917647         0.908345        0.031195                6  \n4            0.917647         0.908345        0.031195                6  \n5            0.917647         0.908345        0.031195                6  \n6            0.917647         0.908345        0.031195                6  \n7            0.917647         0.908345        0.031195                6  \n8            0.917647         0.908345        0.031195                6  \n9            0.917647         0.910698        0.032235                4  \n10           0.917647         0.908345        0.031195                6  \n11           0.917647         0.908345        0.031195                6  \n12           0.917647         0.908345        0.031195                6  \n13           0.917647         0.908345        0.031195                6  \n14           0.917647         0.908345        0.031195                6  \n15           0.964706         0.952969        0.030710                3  \n16           0.964706         0.957674        0.025375                2  \n17           0.964706         0.957702        0.021868                1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_C</th>\n      <th>param_l1_ratio</th>\n      <th>param_penalty</th>\n      <th>param_solver</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.674945</td>\n      <td>0.153823</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 0.1, 'l1_ratio': 0.2, 'penalty': 'elasti...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.598247</td>\n      <td>0.025637</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>0.5</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 0.1, 'l1_ratio': 0.5, 'penalty': 'elasti...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.662989</td>\n      <td>0.058078</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>0.8</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 0.1, 'l1_ratio': 0.8, 'penalty': 'elasti...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.929412</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.910698</td>\n      <td>0.032235</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.707812</td>\n      <td>0.090939</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 1, 'l1_ratio': 0.2, 'penalty': 'elasticn...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.624772</td>\n      <td>0.021910</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 1, 'l1_ratio': 0.5, 'penalty': 'elasticn...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.623691</td>\n      <td>0.030731</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 1, 'l1_ratio': 0.8, 'penalty': 'elasticn...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.701795</td>\n      <td>0.031361</td>\n      <td>0.003125</td>\n      <td>0.006249</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 10, 'l1_ratio': 0.2, 'penalty': 'elastic...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.794977</td>\n      <td>0.052686</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>0.5</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 10, 'l1_ratio': 0.5, 'penalty': 'elastic...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.633363</td>\n      <td>0.025593</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>0.8</td>\n      <td>elasticnet</td>\n      <td>saga</td>\n      <td>{'C': 10, 'l1_ratio': 0.8, 'penalty': 'elastic...</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.588053</td>\n      <td>0.020702</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>l1</td>\n      <td>saga</td>\n      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.929412</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.910698</td>\n      <td>0.032235</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.538070</td>\n      <td>0.083039</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>l2</td>\n      <td>saga</td>\n      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.662105</td>\n      <td>0.105800</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>l1</td>\n      <td>saga</td>\n      <td>{'C': 1, 'penalty': 'l1', 'solver': 'saga'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.455993</td>\n      <td>0.019478</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>l2</td>\n      <td>saga</td>\n      <td>{'C': 1, 'penalty': 'l2', 'solver': 'saga'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.628303</td>\n      <td>0.015658</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>l1</td>\n      <td>saga</td>\n      <td>{'C': 10, 'penalty': 'l1', 'solver': 'saga'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.458909</td>\n      <td>0.012996</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>l2</td>\n      <td>saga</td>\n      <td>{'C': 10, 'penalty': 'l2', 'solver': 'saga'}</td>\n      <td>0.953488</td>\n      <td>0.858824</td>\n      <td>0.917647</td>\n      <td>0.894118</td>\n      <td>0.917647</td>\n      <td>0.908345</td>\n      <td>0.031195</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.318256</td>\n      <td>0.036306</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>l2</td>\n      <td>lbfgs</td>\n      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n      <td>0.988372</td>\n      <td>0.929412</td>\n      <td>0.905882</td>\n      <td>0.976471</td>\n      <td>0.964706</td>\n      <td>0.952969</td>\n      <td>0.030710</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.685107</td>\n      <td>0.028028</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>l2</td>\n      <td>lbfgs</td>\n      <td>{'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n      <td>0.988372</td>\n      <td>0.941176</td>\n      <td>0.917647</td>\n      <td>0.976471</td>\n      <td>0.964706</td>\n      <td>0.957674</td>\n      <td>0.025375</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.277492</td>\n      <td>0.370640</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>l2</td>\n      <td>lbfgs</td>\n      <td>{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n      <td>0.976744</td>\n      <td>0.952941</td>\n      <td>0.917647</td>\n      <td>0.976471</td>\n      <td>0.964706</td>\n      <td>0.957702</td>\n      <td>0.021868</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid1 = [\n",
    "    {'solver': ['saga'], 'C': [0.1, 1, 10], 'penalty': ['elasticnet'], 'l1_ratio': [0.2, 0.5, 0.8]},\n",
    "    {'solver': ['saga'], 'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']},\n",
    "    {'solver': ['lbfgs'], 'C': [0.1, 1, 10], 'penalty': ['l2']}\n",
    "]\n",
    "grid_search1 = GridSearchCV(LogisticRegression(max_iter=10000), param_grid1, cv=5)\n",
    "grid_search1.fit(X_trainval, y_trainval)\n",
    "\n",
    "print('best param values: {}'.format(grid_search1.best_params_))\n",
    "print('best cross-val accuracy value: {:.2f}'.format(grid_search1.best_score_))\n",
    "\n",
    "ress1 = pd.DataFrame(grid_search1.cv_results_)\n",
    "ress1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T03:56:33.200008400Z",
     "start_time": "2023-12-05T03:55:34.424841600Z"
    }
   },
   "id": "85a89bf42ea7d785"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def nested_cv(X, y, inner_cv, outer_cv, Classifier, parameter_grid):\n",
    "    outer_scores = []\n",
    "\n",
    "    for training_samples, test_samples in outer_cv.split(X, y):\n",
    "\n",
    "        best_score = -np.inf\n",
    "        for parameters in parameter_grid:\n",
    "            cv_scores = []\n",
    "\n",
    "            for inner_train, inner_test in inner_cv.split(X[training_samples], y[training_samples]):\n",
    "                clf = Classifier(**parameters)\n",
    "                clf.fit(X[inner_train], y[inner_train])\n",
    "                score = clf.score(X[inner_test], y[inner_test])\n",
    "                cv_scores.append(score)\n",
    "            mean_score = np.mean(cv_scores)\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_params = parameters\n",
    "\n",
    "        clf = Classifier(**best_params)\n",
    "        clf.fit(X[training_samples], y[training_samples])\n",
    "        outer_scores.append(clf.score(X[test_samples], y[test_samples]))\n",
    "    return np.array(outer_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T04:11:35.758587800Z",
     "start_time": "2023-12-05T04:11:35.727318200Z"
    }
   },
   "id": "8f76ddd88fb7f27c"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation accuracy values: [0.93859649 0.93859649 0.97368421 0.94736842 0.95575221]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
    "\n",
    "sco = nested_cv(breast_cancer.data, breast_cancer.target, StratifiedKFold(5), StratifiedKFold(5), SVC,\n",
    "                ParameterGrid(param_grid))\n",
    "\n",
    "print('cross validation accuracy values: {}'.format(sco))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T04:21:46.640822500Z",
     "start_time": "2023-12-05T04:16:44.067648100Z"
    }
   },
   "id": "cbe8edf0444cd74e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style:color='green'>Model Evaluation Metrics</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1174d8924ecbb251"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([212, 357], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 212 examples belonging to class 0, 357 examples of class 1\n",
    "# slightly imbalances dataset (63% - class 1, 37% - class 0)\n",
    "\n",
    "print(np.unique(y, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T05:50:10.883393500Z",
     "start_time": "2023-12-05T05:50:10.852175800Z"
    }
   },
   "id": "695598bb5ad45839"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the trained model is 0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\PycharmProjects\\BigDataLabs\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg.fit(X, y)\n",
    "y_pred = logreg.predict(X)\n",
    "print('accuracy of the trained model is', round(accuracy_score(y, y_pred), 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:02:48.175071700Z",
     "start_time": "2023-12-05T06:02:47.606557900Z"
    }
   },
   "id": "cec901fa95a88f2d"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 50, 357], dtype=int64))\n",
      "(array([1]), array([407], dtype=int64))\n",
      "accuracy of the dummy classifier is 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# remove some data in malignant class and then train new data\n",
    "X_malignant = X[y == 0]\n",
    "y_malignant = y[y == 0]\n",
    "X_benign = X[y == 1]\n",
    "y_benign = y[y == 1]\n",
    "X_new = np.r_[X_benign, X_malignant[:50]]\n",
    "y_new = np.r_[y_benign, y_malignant[:50]]\n",
    "print(np.unique(y_new, return_counts=True))\n",
    "\n",
    "# dummy classifier always predicts the most frequent value occurred in the training set and its accuracy of 88%.\n",
    "# which means that the accuracy can't be used to evaluate model trained on imbalanced data set\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_new, y_new)\n",
    "pred_dummy = dummy.predict(X_new)\n",
    "\n",
    "print(np.unique(pred_dummy, return_counts=True))\n",
    "print('accuracy of the dummy classifier is', round(accuracy_score(y_new, pred_dummy), 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:13:30.195263100Z",
     "start_time": "2023-12-05T06:13:30.155371800Z"
    }
   },
   "id": "a9a8b7c6f509e259"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200  12]\n",
      " [  9 348]]\n",
      "accuracy score of the model is 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# the log reg model correctly classified 200 out of 212 examples as malignant tumor and 348 out of 357 as benign\n",
    "# 12 of the harmful tumors were predicted as harmless and 9 harmless ones as harmful\n",
    "matrix_c = confusion_matrix(y, y_pred)\n",
    "print(matrix_c)\n",
    "print('accuracy score of the model is', round(accuracy_score(y_pred, y), 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:08:25.195166600Z",
     "start_time": "2023-12-05T07:08:25.163924300Z"
    }
   },
   "id": "4853a3d68515d8bb"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(matrix_c, annot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:10:11.800342400Z",
     "start_time": "2023-12-05T07:10:11.153313700Z"
    }
   },
   "id": "ef22b1421a05a890"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       212\n",
      "           1       0.97      0.97      0.97       357\n",
      "\n",
      "    accuracy                           0.96       569\n",
      "   macro avg       0.96      0.96      0.96       569\n",
      "weighted avg       0.96      0.96      0.96       569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:11:56.648133500Z",
     "start_time": "2023-12-05T07:11:56.523083Z"
    }
   },
   "id": "e8c0575cd356f88f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
